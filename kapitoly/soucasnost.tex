\chapter{Současný přístup k optimalizaci vsázek}
\label{ch:soucasnost}
spam and eggs
%% odkazat se na predchozi -- shrnout, proc nechceme delat analyticky vypocet



\section{Heuristiky}
spam and eggs

\subsection{Estimated Distribution}
spam and eggs
%% vzdy odkaz na clanek, popis metody, jak se tim dela LPopt, zkusenosti z provozu, 
% vyhody/nevyhody, porovnani rychlosti
% dobre, ze navyzaduje lokalitu -- zvladne to s ni i bez ni
% viz roubalik, mozna
% rychly popis -- Cptr, upravuje se -- iterativne se uprasnuje odhad distribuce, v danou chvili skonci
% + indove

\subsection{Tabu search}
spam and eggs
% Parks + N. Hill(nove, relativne)

\subsection{Particle Swarm}
spam and eggs
%% vzdy odkaz na clanek, popis metody, jak se tim dela LOopt, zkusenosti z provozu, 
% vyhody/nevyhody, porovnani rychlosti
% dobre, ze navyzaduje lokalitu -- zvladne to s ni i bez ni
% nejake iranske clanky, 
\subsection{Ant Colony}
spam and eggs

\subsection{Simulated Annealing}
spam and eggs
% kropaczek, parks
% SA + MOSA
% Nemaji tu neco i Korejci?
\subsection{Polar Bear Optimization}
% google scholar: loading pattern optimization
\subsection{Gravitational optimization}
% iranci

%% core physics heuristics -- izraelci
%% discrete differential evolution -- cinani
%% deterministic method -- USA

\section{NF kódy}
%%zminit, jak funguji, jake maji verze, kde se pouzivaji, jak jsou rychle aj.
\subsection{Andrea}
%% ETE-use
%% UJV-made
% nodalni
% co zere, co plive, cim to pocita?

\subsection{Moby-Dick}
% EDU-used
% Skoda Plzen -- made


\section{Aproximatory}

\subsection{Deep Neural Networks}
Schlunz \cite[schlunz] používal ANN k predikci parametrů vsázek pro SAFARI-1. Konkretně 1 hidden layer s 200 neurony typu tanh, vstup 26 parametrů 
(hmotnost 235U v každé kazetě), 1 výstupní parametr (konkrétní objective function vsázky -- nevyrovnání,...). Trénovací soubor 20 000 vsázek 
s 17k trénovacími a 3k testovacími. Pro daný cyklus (předpověď na stejné kazety, na kterých se trénovalo) byla do 2 \%, na jiných kazetách už 
bylo nepoužitelné (chyba v průměru až \~ 17 \%). Urychlení odhadu odezev vsázek řádově 10E+4. Dalším důležitým poznatkem bylo, že 
data k trénování byla získána Fisher-Yatesovým mícháním, tedy algoritmem generujícím náhodné permutace s uniformním rozdělením. 

Taková strategie se může vyplatit v případě, že chceme propočítat řádově 10E+5 vsázek a více -- protože na samotné natrénování by bylo potřeba \~ 10E+4 až 
10E+5 vsázek. 

Nabízí se úvaha, zda by nešlo natrénovat aproximátor univerzální (fungující i pro jiné cykly, než na které byl natrénován). To teoreticky není 
vyloučeno, prakticky je nutnou podmínkou sestavit dostatečně variabilní výstupní data -- v tomto případě napočítat vsázky sestavené z velkého 
množství různých kazet\footnotei{.}{V praktickém provozu taková data nevznikají -- jednak dostupných kazet pro každý cyklus je omezeně, 
jednak optimalizační algoritmus poměrně rychle konverguje ke konkrétním hodnotám.}
%%turecky clanek
% Schlunz phd

\section{Potenciál k zlepšení}
%% ucelova funkce je napr. Andrea 2D -- funguje velmi dobře, vzhledem ke svému účelu však je pomalá -- dá se uvažovat 
%% o aproximátoru -- třeba neuronce

% 
% -- zmínit, jak se to dělá dneska
% -- -- analytický výpočet -- viz Google Scholar - K. Smith
% -- -- -- difuzka, transp. teorie, ... proč je špatně použitelné
% 
% -- -- kody -- Andrea, Moby -- jak funguji, co delaji, vyhody/nevyhody
% -- -- -- co na nich chceme upravit -- kdybychom měli lokalitu, muzeme ..., ..., ...
% 
% -- -- optimalizacni algoritmy -- geneticke, simul. zihani, mravenci cesty, ...
% Fejt, Roubalik, spousta článků 
% 
